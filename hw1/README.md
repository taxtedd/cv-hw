# Домашнее задание 1: Тренировочный цикл и linear probe на ViT-Tiny

## Описание

В данном задании сравниваются две архитектуры нейронных сетей для классификации изображений:
- **CNN** - сверточная нейронная сеть, обученная с нуля
- **ViT-Tiny (linear probe)** - Vision Transformer с замороженным энкодером и обученным линейным классификатором

## Структура репозитория
```
hw1/
├── hw1.ipynb # ноутбук с кодом
├── runs/          
│   ├── cnn/
│   │   ├── logs/ # логи TensorBoard
│   │   └── profiler/ # trace профайлера
│   └── vit/
│       ├── logs/ # логи TensorBoard
│       └── profiler/ # trace профайлера
├── results/
│   ├── cnn/
│   │   ├── cm_norm.png # CNN confusion matrix нормированная
│   │   └── cm.png # CNN confusion matrix
│   └── vit/
│   |   ├── cm_norm.png # ViT confusion matrix нормированная
│   |   └── cm.png # ViT confusion matrix
│   ├── model_metrics_comparison.csv # сравнение метрик моделей
│   └── model_profile_comparison.csv # сравнение ресурсов моделей
├── requirements.txt
└── README.md
```

## Установка и запуск

### 1. Подключение к Colab

1. Необходимо открыть `hw1.ipynb` в Google Colab.
2. В меню выбрать **Runtime → Change runtime type** и убедиться, что выбран **GPU** для ускоренной тренировки.


### 2. Установка зависимостей
Перед запуском ноутбука, необходимо установить зависимости, затем последовательно запустить все ячейки.

```
!pip install -r requirements.txt
```

## Подготовка данных
Использован датасет **CIFAR-10** (10 классов), сохраненный в формате ImageFolder.  

К данным применялись аугментации:
- `RandomResizedCrop(32)`  
- `RandomHorizontalFlip()`  
- `Нормализация в соответсвии с типом модели` 

## Обучение моделей
- Перед полноценным обучением модели прошли `sanity-check` (Accuracy после обучения на 3 батчах равна 1, что значит, что данные корректы и модели готовы к обучению)
- В начале обучения собирается trace на 50 шагов.
- Весь процесс обучения логируется в TensorBoard: loss, accuracy, learning rate, гистограммы весов и градиентов.

## Эксперимент 1: CNN

### Структура модели:

- 3 сверточных слоя с 32, 64 и 128 фильтрами, каждый с ядром 3×3 и активацией LeakyReLU.
- После каждого свёрточного слоя применяется MaxPool2d(2).
- Функция активации: `LeakyReLu` 

### Результаты на тесте:
accuracy ~ 67%, macro F1 ~ 67%

## Эксперимент 2: ViT-Tiny (linear probe)

### Структура модели:

- Предобученный ViT-Tiny (vit_tiny_patch16_224).
- Все слои заморожены, обучается только линейная классификационная голова на 10 классов.
- Используется шедулер CosineAnnealingLR для плавного уменьшения шага обучения, что стабилизирует обучение на предобученных весах.

### Результаты на тесте:
accuracy ~ 68%, macro F1 ~ 69%

## Сравнение моделей:
**Сходимость:** CNN сходится быстрее.

**Обощение:** ViT показывает лучшее обобщение, минимальный разрыв между Train/Val.

**Производительность:** CNN требует меньше памяти и ресурсов.

Количество операций: CNN 32,402 vs ViT 71,956 (ViT требует в 2.2 раза больше операций)

**Узкие места:**

- CNN чувствительна к learning rate/batch size, требует регуляризации и аугментаций для улучшения обобщения
- ViT-Tiny требует много ресурсов и времени

## Вывод:
У меня в экспериментах ViT linear probe незначительно превосходит CNN по качеству, вероятно, из-за использования простого датасета с маленькими изображениями (32*32).

Но в целом ViT linear probe выигрывает у CNN по качеству, но она дорогая по ресурсам и медленная. Поэтому использовать CNN часто может быть выгоднее.
